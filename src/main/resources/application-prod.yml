spring:
  application:
    name: ai-fundamentals
  ai:
    openai:
      api-key: ${OPEN_AI_API_KEY}
      chat:
        options:
          model: ${AI_MODEL:gpt-4.1-nano}
          temperature: ${AI_TEMPERATURE:0.7}
  lifecycle:
    timeout-per-shutdown-phase: 30s
  cache:
    type: caffeine
  jpa:
    show-sql: false
    hibernate:
      ddl-auto: validate
  jmx:
    enabled: ${JMX_ENABLED:true}
  task:
    execution:
      pool:
        core-size: ${TASK_POOL_CORE_SIZE:8}
        max-size: ${TASK_POOL_MAX_SIZE:32}
        queue-capacity: ${TASK_POOL_QUEUE_CAPACITY:1000}
        keep-alive: ${TASK_POOL_KEEP_ALIVE:60s}
    scheduling:
      pool:
        size: ${SCHEDULING_POOL_SIZE:4}

server:
  shutdown: graceful
  port: ${SERVER_PORT:8080}
  compression:
    enabled: true
    mime-types: text/html,text/xml,text/plain,text/css,text/javascript,application/javascript,application/json
    min-response-size: 1024
  http2:
    enabled: true
  error:
    include-stacktrace: never
    include-message: always

# Production logging configuration
logging:
  level:
    '[com.srihari.ai]': ${LOG_LEVEL:INFO}
    '[org.springframework.ai]': WARN
    '[reactor.netty]': WARN
    '[org.springframework.web]': WARN
    '[org.springframework.security]': WARN
    '[org.springframework.boot]': WARN
    '[org.hibernate]': WARN
  config: classpath:logback-spring.xml
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [%X{correlationId:-}] %logger{36} - %msg%n"

# Production resilience configuration
resilience4j:
  circuitbreaker:
    instances:
      openai:
        registerHealthIndicator: true
        slidingWindowSize: ${CIRCUIT_BREAKER_WINDOW_SIZE:20}
        minimumNumberOfCalls: ${CIRCUIT_BREAKER_MIN_CALLS:10}
        permittedNumberOfCallsInHalfOpenState: 5
        waitDurationInOpenState: ${CIRCUIT_BREAKER_WAIT_DURATION:30s}
        failureRateThreshold: ${CIRCUIT_BREAKER_FAILURE_RATE:60}
        automaticTransitionFromOpenToHalfOpenEnabled: true
        slowCallRateThreshold: 80
        slowCallDurationThreshold: 10s
      chatCompletionCB:
        registerHealthIndicator: true
        slidingWindowSize: ${CIRCUIT_BREAKER_WINDOW_SIZE:20}
        minimumNumberOfCalls: ${CIRCUIT_BREAKER_MIN_CALLS:10}
        permittedNumberOfCallsInHalfOpenState: 5
        waitDurationInOpenState: ${CIRCUIT_BREAKER_WAIT_DURATION:30s}
        failureRateThreshold: ${CIRCUIT_BREAKER_FAILURE_RATE:60}
        automaticTransitionFromOpenToHalfOpenEnabled: true
        slowCallRateThreshold: 80
        slowCallDurationThreshold: 10s
  ratelimiter:
    instances:
      api:
        limitForPeriod: ${RATE_LIMIT_API:100}
        limitRefreshPeriod: 60s
        timeoutDuration: 5s
      web:
        limitForPeriod: ${RATE_LIMIT_WEB:200}
        limitRefreshPeriod: 60s
        timeoutDuration: 2s
      openai:
        limitForPeriod: ${RATE_LIMIT_OPENAI:50}
        limitRefreshPeriod: 60s
        timeoutDuration: 10s
  bulkhead:
    instances:
      ai-service:
        maxConcurrentCalls: ${BULKHEAD_MAX_CALLS:50}
        maxWaitDuration: 5s
  timelimiter:
    instances:
      ai-service:
        timeoutDuration: ${TIMEOUT_DURATION:60s}
        cancelRunningFuture: true
  retry:
    instances:
      openai:
        maxAttempts: 3
        waitDuration: 1s
        exponentialBackoffMultiplier: 2
        retryExceptions:
          - java.net.ConnectException
          - java.net.SocketTimeoutException
          - org.springframework.web.reactive.function.client.WebClientRequestException

# Production application configuration
app:
  logging:
    level: ${LOG_LEVEL:INFO}
    json-enabled: ${JSON_LOGGING_ENABLED:true}
    request-logging-enabled: ${REQUEST_LOGGING_ENABLED:true}
    performance-logging-enabled: ${PERFORMANCE_LOGGING_ENABLED:true}
    log-sensitive-data: false
    max-message-length: ${MAX_LOG_MESSAGE_LENGTH:2000}
    include-stack-trace: false
    trace-method-calls: false
    slow-operation-threshold-ms: ${SLOW_OPERATION_THRESHOLD:2000}
  events:
    notifications:
      enabled: ${NOTIFICATIONS_ENABLED:true}
  rate-limiting:
    api:
      limit-for-period: ${RATE_LIMIT_API:100}
      limit-refresh-period: 60s
      timeout-duration: 5s
    web:
      limit-for-period: ${RATE_LIMIT_WEB:200}
      limit-refresh-period: 60s
      timeout-duration: 2s
    open-ai:
      limit-for-period: ${RATE_LIMIT_OPENAI:50}
      limit-refresh-period: 60s
      timeout-duration: 10s
  webclient:
    timeout:
      connect: ${WEBCLIENT_CONNECT_TIMEOUT:10s}
      read: ${WEBCLIENT_READ_TIMEOUT:60s}
      write: ${WEBCLIENT_WRITE_TIMEOUT:30s}
      response: ${WEBCLIENT_RESPONSE_TIMEOUT:120s}
    connection-pool:
      max-connections: ${CONNECTION_POOL_MAX:200}
      max-idle-time: ${CONNECTION_POOL_IDLE_TIME:60}
      max-life-time: ${CONNECTION_POOL_LIFE_TIME:300}
      pending-acquire-timeout: ${CONNECTION_POOL_ACQUIRE_TIMEOUT:30s}
    bulkhead:
      max-concurrent-calls: ${BULKHEAD_MAX_CALLS:50}
      max-wait-duration: 10s
  cache:
    conversation:
      maximum-size: ${CACHE_CONVERSATION_SIZE:5000}
      expire-after-write: ${CACHE_CONVERSATION_EXPIRE_WRITE:4h}
      expire-after-access: ${CACHE_CONVERSATION_EXPIRE_ACCESS:1h}
      refresh-after-write: ${CACHE_CONVERSATION_REFRESH:30m}
    response:
      maximum-size: ${CACHE_RESPONSE_SIZE:2000}
      expire-after-write: ${CACHE_RESPONSE_EXPIRE_WRITE:1h}
      expire-after-access: ${CACHE_RESPONSE_EXPIRE_ACCESS:30m}
    model:
      maximum-size: ${CACHE_MODEL_SIZE:500}
      expire-after-write: ${CACHE_MODEL_EXPIRE_WRITE:2h}
  graceful-shutdown:
    enabled: true
    timeout: ${GRACEFUL_SHUTDOWN_TIMEOUT:60s}
    connection-drain-timeout: ${CONNECTION_DRAIN_TIMEOUT:30s}
    wait-for-active-requests: true
  security:
    cors:
      allowed-origins: ${CORS_ALLOWED_ORIGINS:}
      allowed-methods: ${CORS_ALLOWED_METHODS:GET,POST,PUT,DELETE,OPTIONS}
      allowed-headers: ${CORS_ALLOWED_HEADERS:*}
      allow-credentials: ${CORS_ALLOW_CREDENTIALS:false}
      max-age: ${CORS_MAX_AGE:3600}
    rate-limit:
      enabled: ${RATE_LIMITING_ENABLED:true}
      per-ip-limit: ${RATE_LIMIT_PER_IP:1000}
      per-ip-window: ${RATE_LIMIT_PER_IP_WINDOW:3600s}
    headers:
      content-security-policy: ${CSP_HEADER:default-src 'self'; script-src 'self' 'unsafe-inline'; style-src 'self' 'unsafe-inline'; img-src 'self' data:; font-src 'self'}
      strict-transport-security: ${HSTS_HEADER:max-age=31536000; includeSubDomains}
      x-frame-options: ${X_FRAME_OPTIONS:DENY}
      x-content-type-options: ${X_CONTENT_TYPE_OPTIONS:nosniff}
      referrer-policy: ${REFERRER_POLICY:strict-origin-when-cross-origin}
  feature-flags:
    advanced-logging: ${FEATURE_ADVANCED_LOGGING:true}
    caching: ${FEATURE_CACHING:true}
    rate-limiting: ${FEATURE_RATE_LIMITING:true}
    circuit-breaker: ${FEATURE_CIRCUIT_BREAKER:true}
    metrics: ${FEATURE_METRICS:true}
    tracing: ${FEATURE_TRACING:false}
    notifications: ${FEATURE_NOTIFICATIONS:true}
    security-headers: ${FEATURE_SECURITY_HEADERS:true}

# Production monitoring and management
management:
  endpoints:
    web:
      exposure:
        include: health,metrics,prometheus,info
      base-path: /actuator
  endpoint:
    health:
      show-details: when-authorized
      show-components: when-authorized
      roles: ADMIN
    metrics:
      access: UNRESTRICTED
    prometheus:
      access: UNRESTRICTED
    info:
      access: UNRESTRICTED
  health:
    circuitbreakers:
      enabled: true
    diskspace:
      enabled: true
      threshold: ${HEALTH_DISK_THRESHOLD:10GB}
    db:
      enabled: false
  prometheus:
    metrics:
      export:
        enabled: true
        step: ${METRICS_STEP:30s}
        descriptions: true
        pushgateway:
          enabled: false
  metrics:
    distribution:
      percentiles-histogram:
        '[http.server.requests]': true
        '[chat.api.duration]': true
        '[openai.api.duration]': true
        '[api.operation.duration]': true
        '[conversation.duration]': true
        '[ai.model.latency]': true
        '[cache.gets]': true
        '[cache.puts]': true
        '[connection.pool.acquisition.time]': true
      percentiles:
        '[http.server.requests]': 0.5, 0.95, 0.99
        '[chat.api.duration]': 0.5, 0.95, 0.99
        '[openai.api.duration]': 0.5, 0.95, 0.99
        '[api.operation.duration]': 0.5, 0.95, 0.99
        '[conversation.duration]': 0.5, 0.95, 0.99
        '[ai.model.latency]': 0.5, 0.95, 0.99
      slo:
        '[http.server.requests]': 100ms, 500ms, 1s, 2s, 5s
        '[chat.api.duration]': 1s, 5s, 10s, 30s
        '[openai.api.duration]': 1s, 5s, 10s, 30s
        '[api.operation.duration]': 500ms, 1s, 5s, 10s
        '[conversation.duration]': 1m, 5m, 15m, 30m
        '[ai.model.latency]': 500ms, 1s, 5s, 10s
    tags:
      application: ${spring.application.name}
      environment: ${ENVIRONMENT:production}
      version: ${APPLICATION_VERSION:unknown}
      instance: ${HOSTNAME:${random.uuid}}
      service: ai-fundamentals
      datacenter: ${DATACENTER:unknown}
      region: ${AWS_REGION:unknown}


  tracing:
    enabled: ${TRACING_ENABLED:false}
    sampling:
      probability: ${TRACING_SAMPLING_RATE:0.1}
    baggage:
      correlation:
        enabled: true
        fields: correlationId
      remote-fields: correlationId
  zipkin:
    tracing:
      endpoint: ${ZIPKIN_ENDPOINT:http://zipkin:9411/api/v2/spans}

# JVM and performance tuning for production
# (Merged with main spring configuration above)